{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "\n",
    "# Load the model and tokenizer\n",
    "class CONFIG:\n",
    "    model_name:str = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "    dataset_path: str = \"data\"\n",
    "    init_result_path: str = \"results\"\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG.model_name)\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(CONFIG.model_name)\n",
    "\n",
    "def llama3_8b_corrective_prompt(problem, previous_solution, correction_hint):\n",
    "    \"\"\"\n",
    "    Perform corrective prompting using Llama3 8B model.\n",
    "\n",
    "    Parameters:\n",
    "    problem (str): The problem statement.\n",
    "    previous_solution (str): The previous incorrect solution.\n",
    "    correction_hint (str): The hint or correction to guide the model.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated solution.\n",
    "    \"\"\"\n",
    "    prompt = f\"Problem: {problem}\\nPrevious Solution: {previous_solution}\\nCorrection Hint: {correction_hint}\\nNew Solution:\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=150, num_return_sequences=1)  # Adjust max_length as needed\n",
    "    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract the generated solution after \"New Solution:\"\n",
    "    solution = solution.split(\"New Solution:\")[1].strip() if \"New Solution:\" in solution else solution.strip()\n",
    "    return solution\n",
    "\n",
    "def categorize_responses(incorrect_pairs, evaluate_function):\n",
    "    \"\"\"\n",
    "    Categorize responses into accepted and rejected after corrective prompting.\n",
    "\n",
    "    Parameters:\n",
    "    incorrect_pairs (list): List of dictionaries containing incorrect problem-solution pairs.\n",
    "    evaluate_function (callable): The function that evaluates the solution.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing JSON strings of accepted and rejected datasets.\n",
    "    \"\"\"\n",
    "    accepted = []\n",
    "    rejected = []\n",
    "\n",
    "    for item in incorrect_pairs:\n",
    "        problem = item['problem']\n",
    "        expected_solution = item['expected_solution']\n",
    "        previous_solution = item['actual_solution']\n",
    "        correction_hint = f\"The correct solution should be: {expected_solution}\"\n",
    "\n",
    "        new_solution = llama3_8b_corrective_prompt(problem, previous_solution, correction_hint)\n",
    "\n",
    "        if new_solution.strip() == expected_solution.strip():\n",
    "            accepted.append({\n",
    "                'problem': problem,\n",
    "                'expected_solution': expected_solution,\n",
    "                'previous_solution': previous_solution,\n",
    "                'new_solution': new_solution\n",
    "            })\n",
    "        else:\n",
    "            rejected.append({\n",
    "                'problem': problem,\n",
    "                'expected_solution': expected_solution,\n",
    "                'previous_solution': previous_solution,\n",
    "                'new_solution': new_solution\n",
    "            })\n",
    "\n",
    "    accepted_json = json.dumps(accepted, indent=4)\n",
    "    rejected_json = json.dumps(rejected, indent=4)\n",
    "\n",
    "    return accepted_json, rejected_json\n",
    "\n",
    "# Example usage:\n",
    "# Note: Replace the following incorrect_pairs with actual incorrect pairs data\n",
    "incorrect_pairs = [\n",
    "    {'problem': 'If a train travels 60 miles in 1 hour, how far will it travel in 4 hours?', 'expected_solution': '240 miles', 'actual_solution': '250 miles'},\n",
    "    {'problem': 'Sarah has 5 apples. She buys 7 more apples. How many apples does she have now?', 'expected_solution': '12 apples', 'actual_solution': '11 apples'},\n",
    "]\n",
    "\n",
    "accepted_json, rejected_json = categorize_responses(incorrect_pairs, llama3_8b_corrective_prompt)\n",
    "print(\"Accepted Responses JSON:\", accepted_json)\n",
    "print(\"Rejected Responses JSON:\", rejected_json)\n",
    "print(f\"Number of accepted responses: {len(json.loads(accepted_json))}\")\n",
    "print(f\"Number of rejected responses: {len(json.loads(rejected_json))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
