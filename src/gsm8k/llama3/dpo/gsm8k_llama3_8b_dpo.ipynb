{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    model_name:str = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "    dataset_path: str = \"data\"\n",
    "    init_result_path: str = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: 7473\n",
      "Size of test data: 1319\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_gsm8k = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "\n",
    "training_data = dataset_gsm8k['train']\n",
    "test_data = dataset_gsm8k['test']\n",
    "\n",
    "print(f\"Size of training data: {len(training_data)}\")\n",
    "print(f\"Size of test data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG.model_name)\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(CONFIG.model_name)\n",
    "\n",
    "# Define 4-shot chain-of-thought examples\n",
    "cot_examples = [\n",
    "    {\"problem\": \"If a train travels 60 miles in 1 hour, how far will it travel in 4 hours?\", \n",
    "     \"solution\": \"First, calculate the distance traveled in one hour, which is 60 miles. Since the train travels at a constant speed, in 4 hours, it will travel 4 times the distance of one hour. Therefore, the solution is 60 miles * 4 = 240 miles.\"},\n",
    "    {\"problem\": \"Sarah has 5 apples. She buys 7 more apples. How many apples does she have now?\", \n",
    "     \"solution\": \"First, note that Sarah initially has 5 apples. Then, she buys 7 more apples. To find the total number of apples Sarah has, add the apples she had initially to the apples she bought. Therefore, the solution is 5 + 7 = 12 apples.\"},\n",
    "    {\"problem\": \"Tom has 8 candies. He gives 3 candies to his friend. How many candies does Tom have left?\", \n",
    "     \"solution\": \"First, note that Tom starts with 8 candies. He gives away 3 candies. To find out how many candies Tom has left, subtract the number of candies he gives away from the number he started with. Therefore, the solution is 8 - 3 = 5 candies.\"},\n",
    "    {\"problem\": \"A rectangle has a length of 10 cm and a width of 5 cm. What is the area of the rectangle?\", \n",
    "     \"solution\": \"First, note that the area of a rectangle is calculated by multiplying its length by its width. Given the length is 10 cm and the width is 5 cm, the area is 10 cm * 5 cm. Therefore, the solution is 10 * 5 = 50 square cm.\"}\n",
    "]\n",
    "\n",
    "def llama3_8b_evaluate(problem):\n",
    "    \"\"\"\n",
    "    Evaluate the solution using Llama3 8B model with 4-shot CoT examples.\n",
    "\n",
    "    Parameters:\n",
    "    problem (str): The problem statement.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated solution.\n",
    "    \"\"\"\n",
    "    # Construct the prompt with 4-shot CoT examples\n",
    "    prompt = \"\"\n",
    "    for example in cot_examples:\n",
    "        prompt += f\"Problem: {example['problem']}\\nSolution: {example['solution']}\\n\\n\"\n",
    "    prompt += f\"Problem: {problem}\\nSolution:\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=150, num_return_sequences=1)  # Adjust max_length as needed\n",
    "    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract the generated solution after \"Solution:\"\n",
    "    solution = solution.split(\"Solution:\")[1].strip() if \"Solution:\" in solution else solution.strip()\n",
    "    return solution\n",
    "\n",
    "def run_eval(evaluate_function, test_data):\n",
    "    \"\"\"\n",
    "    Run initial evaluation to find the accuracy of the result without alignment\n",
    "    and return the incorrect problem-solution pairs in JSON format.\n",
    "\n",
    "    Parameters:\n",
    "    evaluate_function (callable): The function that evaluates the solution.\n",
    "    test_data (list): A list of dictionaries where each dictionary contains 'problem' and 'expected_solution'.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing accuracy and JSON string of incorrect problem-solution pairs.\n",
    "    \"\"\"\n",
    "    total = len(test_data)\n",
    "    incorrect_pairs = []\n",
    "    correct_count = 0\n",
    "\n",
    "    for item in test_data:\n",
    "        problem = item['problem']\n",
    "        expected_solution = item['expected_solution']\n",
    "        actual_solution = evaluate_function(problem)\n",
    "\n",
    "        if actual_solution.strip() == expected_solution.strip():\n",
    "            correct_count += 1\n",
    "        else:\n",
    "            incorrect_pairs.append({\n",
    "                'problem': problem,\n",
    "                'expected_solution': expected_solution,\n",
    "                'actual_solution': actual_solution\n",
    "            })\n",
    "\n",
    "    accuracy = correct_count / total\n",
    "    incorrect_pairs_json = json.dumps(incorrect_pairs, indent=4)\n",
    "\n",
    "    return accuracy, incorrect_pairs_json\n",
    "\n",
    "def save_incorrect_pairs(file_path=\"./\", file_name=\"incorrect_pairs.json\"):\n",
    "    with open(file_path + file_name, \"w\") as file:\n",
    "        file.write(incorrect_pairs_json)\n",
    "    \n",
    "    print(f\"Incorrect problem-solution pairs saved to {file_path}\")\n",
    "\n",
    "accuracy, incorrect_pairs_json = run_eval(llama3_8b_evaluate, test_data)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Incorrect Problem-Solution Pairs JSON:\", incorrect_pairs_json)\n",
    "save_incorrect_pairs(\"llama_3_8b_4shots_cot_gsm8k_incorrect_pairs.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
